{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "50944570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.10\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d41e03-6f07-49c3-a028-63d0bcf6867c",
   "metadata": {
    "id": "16d41e03-6f07-49c3-a028-63d0bcf6867c"
   },
   "source": [
    "IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "25396635-459d-4978-ba53-5953fde5a395",
   "metadata": {
    "id": "25396635-459d-4978-ba53-5953fde5a395"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import xgboost as xgb\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ce2c8b-926b-44bf-935f-cb0d0cad1029",
   "metadata": {
    "id": "71ce2c8b-926b-44bf-935f-cb0d0cad1029"
   },
   "source": [
    "STANDARDIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7bf911c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_parquet('../processed_data/X_train.parquet')\n",
    "X_val = pd.read_parquet('../processed_data/X_val.parquet')\n",
    "\n",
    "y_train = np.loadtxt('../processed_data/y_train.txt').astype(int)\n",
    "y_val = np.loadtxt('../processed_data/y_val.txt').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d9f2d6e2-1c27-4c17-ad7f-011d63784581",
   "metadata": {
    "id": "d9f2d6e2-1c27-4c17-ad7f-011d63784581"
   },
   "outputs": [],
   "source": [
    "# Seperation of columns into numeric and categorical columns\n",
    "num_cols = np.array(X_train.select_dtypes(include= ['int64','float64']).columns).tolist()\n",
    "cat_cols = np.array(X_train.select_dtypes(include= ['category','object']).columns).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6911930c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AGE_GROUP', 'YEARS_EMPLOYED_GROUP', 'PHONE_CHANGE_GROUP']\n",
      "['REGION_RATING_CLIENT_W_CITY', 'REGION_RATING_CLIENT', 'EXT_SOURCE_3', 'EXT_SOURCE_2', 'EXT_SOURCE_1', 'FLOORSMAX_AVG']\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "print(cat_cols)\n",
    "print(num_cols)\n",
    "print(set(cat_cols + num_cols) - set(X_train.columns))  # Should be empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d7133ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dicts = X_train[cat_cols + num_cols].to_dict(orient='records')\n",
    "val_dicts = X_val[cat_cols + num_cols].to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0adc212c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dv = DictVectorizer()\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "X_val = dv.transform(val_dicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2c18c1",
   "metadata": {},
   "source": [
    "EXPERIMENT TRACKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d7bb7067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/Users/mac/Projects/MLops_credit_default_risk_prediction/02-experiment-tracking/mlruns/1', creation_time=1754811864406, experiment_id='1', last_update_time=1754811864406, lifecycle_stage='active', name='credit_default_risk_experiment_tracking', tags={}>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri('sqlite:///../cred_risk_sqlite_mlflow.db')\n",
    "mlflow.set_experiment('credit_default_risk_experiment_tracking')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e11b6ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.set_tag(\"engineer\", \"adeakinwe\")\n",
    "    mlflow.set_tag(\"model\", \"Logistic Regression\")\n",
    "\n",
    "    mlflow.log_param(\"train_data_path\", \"../processed_data/X_train.parquet\")\n",
    "    mlflow.log_param(\"val_data_path\", \"../processed_data/X_val.parquet\")\n",
    "\n",
    "    lr = LogisticRegression(class_weight='balanced')\n",
    "    lr.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = lr.predict(X_val)\n",
    "    y_proba = lr.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    accuracy = round(accuracy_score(y_val, y_pred), 3)\n",
    "    auc = round(roc_auc_score(y_val, y_proba), 3)\n",
    "\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    mlflow.log_metric(\"auc\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "743c0714",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run():\n",
    "    mlflow.set_tag(\"engineer\", \"adeakinwe\")\n",
    "    mlflow.set_tag(\"model\", \"XGBoost\")\n",
    "\n",
    "    mlflow.log_param(\"train_data_path\", \"../processed_data/X_train.parquet\")\n",
    "    mlflow.log_param(\"val_data_path\", \"../processed_data/X_val.parquet\")\n",
    "\n",
    "    # Prepare DMatrix\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dval = xgb.DMatrix(X_val, label=y_val)\n",
    "\n",
    "    # Compute scale_pos_weight if needed\n",
    "    class_counts = pd.Series(y_train).value_counts()\n",
    "    scale_pos_weight = class_counts[0] / class_counts[1]\n",
    "\n",
    "    # XGBoost params\n",
    "    params = {\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"eval_metric\": \"auc\",\n",
    "        \"scale_pos_weight\": scale_pos_weight,\n",
    "    }\n",
    "\n",
    "    mlflow.log_param(\"scale_pos_weight\", scale_pos_weight)\n",
    "\n",
    "    # Train with early stopping\n",
    "    model = xgb.train(\n",
    "        params=params,\n",
    "        dtrain=dtrain,\n",
    "        num_boost_round=100,\n",
    "        evals=[(dtrain, \"train\"), (dval, \"eval\")],\n",
    "        early_stopping_rounds=50,\n",
    "        verbose_eval=False\n",
    "    )\n",
    "\n",
    "    # Predict and evaluate\n",
    "    y_pred_proba = model.predict(dval)\n",
    "    y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "\n",
    "    accuracy = round(accuracy_score(y_val, y_pred), 3)\n",
    "    auc = round(roc_auc_score(y_val, y_pred_proba), 3)\n",
    "\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    mlflow.log_metric(\"auc\", auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3495dbcd",
   "metadata": {},
   "source": [
    "HYPER-PARAMETER TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0bb7c7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
    "from hyperopt.pyll import scope\n",
    "import mlflow.xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "82c1e082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-auc:0.61075                                  \n",
      "[10]\teval-auc:0.66212                                 \n",
      "[20]\teval-auc:0.66643                                 \n",
      "[30]\teval-auc:0.66567                                 \n",
      "[40]\teval-auc:0.66182                                 \n",
      "[50]\teval-auc:0.65924                                 \n",
      "[60]\teval-auc:0.65760                                 \n",
      "[67]\teval-auc:0.65682                                 \n",
      "  0%|          | 0/50 [00:15<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/10 09:02:11 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-auc:0.60377                                                \n",
      "[10]\teval-auc:0.64307                                               \n",
      "[20]\teval-auc:0.65915                                               \n",
      "[30]\teval-auc:0.66392                                               \n",
      "[40]\teval-auc:0.66588                                               \n",
      "[50]\teval-auc:0.66664                                               \n",
      "[60]\teval-auc:0.66559                                               \n",
      "[70]\teval-auc:0.66545                                               \n",
      "[80]\teval-auc:0.66469                                               \n",
      "[90]\teval-auc:0.66397                                               \n",
      "[100]\teval-auc:0.66226                                              \n",
      "[101]\teval-auc:0.66225                                              \n",
      "  2%|▏         | 1/50 [00:45<18:57, 23.22s/trial, best loss: -0.657]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/10 09:02:40 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-auc:0.61617                                                \n",
      "[10]\teval-auc:0.68345                                               \n",
      "[20]\teval-auc:0.68966                                               \n",
      "[30]\teval-auc:0.68560                                               \n",
      "[40]\teval-auc:0.67814                                               \n",
      "[50]\teval-auc:0.67476                                               \n",
      "[60]\teval-auc:0.67421                                               \n",
      "[66]\teval-auc:0.67189                                               \n",
      "  4%|▍         | 2/50 [00:59<21:17, 26.61s/trial, best loss: -0.662]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/10 09:02:52 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-auc:0.61149                                                \n",
      "[10]\teval-auc:0.64766                                               \n",
      "[20]\teval-auc:0.65107                                               \n",
      "[30]\teval-auc:0.65057                                               \n",
      "[40]\teval-auc:0.64753                                               \n",
      "[50]\teval-auc:0.64580                                               \n",
      "[60]\teval-auc:0.64398                                               \n",
      "[70]\teval-auc:0.64241                                               \n",
      "[74]\teval-auc:0.64211                                               \n",
      "  6%|▌         | 3/50 [01:15<15:28, 19.75s/trial, best loss: -0.672]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/10 09:03:10 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-auc:0.62561                                                \n",
      "[10]\teval-auc:0.69622                                               \n",
      "[20]\teval-auc:0.70061                                               \n",
      "[30]\teval-auc:0.69932                                               \n",
      "[40]\teval-auc:0.69576                                               \n",
      "[50]\teval-auc:0.69286                                               \n",
      "[60]\teval-auc:0.69125                                               \n",
      "[70]\teval-auc:0.68834                                               \n",
      "[72]\teval-auc:0.68802                                               \n",
      "  8%|▊         | 4/50 [01:34<14:41, 19.15s/trial, best loss: -0.672]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/10 09:03:28 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-auc:0.66498                                                \n",
      "[10]\teval-auc:0.64594                                               \n",
      "[20]\teval-auc:0.64085                                               \n",
      "[30]\teval-auc:0.63957                                               \n",
      "[40]\teval-auc:0.63791                                               \n",
      "[49]\teval-auc:0.63610                                               \n",
      " 10%|█         | 5/50 [01:44<14:08, 18.86s/trial, best loss: -0.688]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/10 09:03:36 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-auc:0.61196                                                \n",
      "[10]\teval-auc:0.63177                                               \n",
      "[20]\teval-auc:0.63727                                               \n",
      "[30]\teval-auc:0.63285                                               \n",
      "[40]\teval-auc:0.63242                                               \n",
      "[50]\teval-auc:0.63016                                               \n",
      "[54]\teval-auc:0.63047                                               \n",
      " 12%|█▏        | 6/50 [01:55<11:04, 15.11s/trial, best loss: -0.688]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/10 09:03:47 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-auc:0.61013                                                \n",
      "[10]\teval-auc:0.61171                                               \n",
      "[20]\teval-auc:0.62103                                               \n",
      "[30]\teval-auc:0.61897                                               \n",
      "[40]\teval-auc:0.61932                                               \n",
      "[50]\teval-auc:0.61845                                               \n",
      "[60]\teval-auc:0.62003                                               \n",
      "[70]\teval-auc:0.62159                                               \n",
      " 14%|█▍        | 7/50 [02:11<09:53, 13.80s/trial, best loss: -0.688]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/10 09:04:06 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-auc:0.62131                                                \n",
      "[10]\teval-auc:0.69189                                               \n",
      "[20]\teval-auc:0.69566                                               \n",
      "[30]\teval-auc:0.69340                                               \n",
      "[40]\teval-auc:0.68857                                               \n",
      "[50]\teval-auc:0.68581                                               \n",
      "[60]\teval-auc:0.68441                                               \n",
      "[65]\teval-auc:0.68312                                               \n",
      " 16%|█▌        | 8/50 [02:32<10:43, 15.32s/trial, best loss: -0.688]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/10 09:04:26 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-auc:0.62172                                                \n",
      "[10]\teval-auc:0.68367                                               \n",
      "[20]\teval-auc:0.69071                                               \n",
      "[30]\teval-auc:0.68877                                               \n",
      "[40]\teval-auc:0.68576                                               \n",
      "[50]\teval-auc:0.68247                                               \n",
      "[60]\teval-auc:0.67782                                               \n",
      "[69]\teval-auc:0.67534                                               \n",
      " 18%|█▊        | 9/50 [02:45<11:26, 16.74s/trial, best loss: -0.688]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/10 09:04:38 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-auc:0.61140                                                 \n",
      "[10]\teval-auc:0.62642                                                \n",
      "[20]\teval-auc:0.62581                                                \n",
      "[30]\teval-auc:0.62477                                                \n",
      "[40]\teval-auc:0.62268                                                \n",
      "[50]\teval-auc:0.62291                                                \n",
      "[60]\teval-auc:0.62234                                                \n",
      " 20%|██        | 10/50 [03:03<10:22, 15.57s/trial, best loss: -0.688]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/10 09:04:56 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-auc:0.66077                                                 \n",
      "[10]\teval-auc:0.71332                                                \n",
      "[20]\teval-auc:0.72018                                                \n",
      "[30]\teval-auc:0.72012                                                \n",
      "[40]\teval-auc:0.71830                                                \n",
      "[50]\teval-auc:0.71638                                                \n",
      "[60]\teval-auc:0.71535                                                \n",
      "[70]\teval-auc:0.71373                                                \n",
      "[78]\teval-auc:0.71248                                                \n",
      " 22%|██▏       | 11/50 [03:12<10:26, 16.06s/trial, best loss: -0.688]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/10 09:05:03 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-auc:0.63111                                                 \n",
      "[10]\teval-auc:0.66859                                                \n",
      "[20]\teval-auc:0.66411                                                \n",
      "[30]\teval-auc:0.65709                                                \n",
      "[40]\teval-auc:0.65427                                                \n",
      "[50]\teval-auc:0.65241                                                \n",
      "[54]\teval-auc:0.65280                                                \n",
      " 24%|██▍       | 12/50 [03:21<08:31, 13.46s/trial, best loss: -0.712]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/10 09:05:13 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-auc:0.60179                                                 \n",
      "[10]\teval-auc:0.63845                                                \n",
      "[20]\teval-auc:0.65352                                                \n",
      "[30]\teval-auc:0.66173                                                \n",
      "[40]\teval-auc:0.66508                                                \n",
      "[50]\teval-auc:0.66663                                                \n",
      "[60]\teval-auc:0.66783                                                \n",
      "[70]\teval-auc:0.66817                                                \n",
      "[80]\teval-auc:0.66750                                                \n",
      "[90]\teval-auc:0.66554                                                \n",
      "[100]\teval-auc:0.66498                                               \n",
      "[110]\teval-auc:0.66396                                               \n",
      "[120]\teval-auc:0.66239                                               \n",
      "[122]\teval-auc:0.66246                                               \n",
      " 26%|██▌       | 13/50 [03:55<07:33, 12.25s/trial, best loss: -0.712]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/10 09:05:53 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-auc:0.62405                                                 \n",
      "[10]\teval-auc:0.68876                                                \n",
      "[20]\teval-auc:0.68242                                                \n",
      "[30]\teval-auc:0.67836                                                \n",
      "[40]\teval-auc:0.67368                                                \n",
      "[50]\teval-auc:0.67039                                                \n",
      "[59]\teval-auc:0.66861                                                \n",
      " 28%|██▊       | 14/50 [04:17<12:26, 20.75s/trial, best loss: -0.712]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/10 09:06:11 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-auc:0.60713                                                 \n",
      "[10]\teval-auc:0.67008                                                \n",
      "[20]\teval-auc:0.68185                                                \n",
      "[30]\teval-auc:0.68612                                                \n",
      "[40]\teval-auc:0.68714                                                \n",
      "[50]\teval-auc:0.68322                                                \n",
      "[60]\teval-auc:0.67974                                                \n",
      "[70]\teval-auc:0.67858                                                \n",
      "[80]\teval-auc:0.67757                                                \n",
      "[87]\teval-auc:0.67726                                                \n",
      " 30%|███       | 15/50 [04:36<11:32, 19.78s/trial, best loss: -0.712]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/10 09:06:30 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-auc:0.61349                                                 \n",
      "[10]\teval-auc:0.67704                                                \n",
      "[20]\teval-auc:0.67702                                                \n",
      "[30]\teval-auc:0.67226                                                \n",
      "[40]\teval-auc:0.66848                                                \n",
      "[50]\teval-auc:0.66416                                                \n",
      "[58]\teval-auc:0.66317                                                \n",
      " 32%|███▏      | 16/50 [04:53<11:11, 19.75s/trial, best loss: -0.712]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/10 09:06:45 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-auc:0.62864                                                 \n",
      "[10]\teval-auc:0.69818                                                \n",
      "[20]\teval-auc:0.70745                                                \n",
      "[30]\teval-auc:0.70991                                                \n",
      "[40]\teval-auc:0.70553                                                \n",
      "[50]\teval-auc:0.70270                                                \n",
      "[60]\teval-auc:0.70004                                                \n",
      "[70]\teval-auc:0.69780                                                \n",
      "[79]\teval-auc:0.69500                                                \n",
      " 34%|███▍      | 17/50 [05:06<10:03, 18.28s/trial, best loss: -0.712]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/10 09:06:59 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-auc:0.66608                                                 \n",
      "[10]\teval-auc:0.71111                                                \n",
      "[20]\teval-auc:0.70822                                                \n",
      "[30]\teval-auc:0.70109                                                \n",
      "[40]\teval-auc:0.69657                                                \n",
      "[50]\teval-auc:0.69375                                                \n",
      "[54]\teval-auc:0.69236                                                \n",
      " 36%|███▌      | 18/50 [05:13<08:56, 16.77s/trial, best loss: -0.712]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/10 09:07:04 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-auc:0.65536                                                 \n",
      "[10]\teval-auc:0.67350                                                \n",
      "[20]\teval-auc:0.66664                                                \n",
      "[30]\teval-auc:0.65935                                                \n",
      "[40]\teval-auc:0.65559                                                \n",
      "[50]\teval-auc:0.65394                                                \n",
      "[56]\teval-auc:0.65351                                                \n",
      " 38%|███▊      | 19/50 [05:21<06:54, 13.38s/trial, best loss: -0.712]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/10 09:07:13 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-auc:0.66794                                                 \n",
      "[10]\teval-auc:0.71933                                                \n",
      "[20]\teval-auc:0.72736                                                \n",
      "[30]\teval-auc:0.72803                                                \n",
      "[40]\teval-auc:0.72917                                                \n",
      "[50]\teval-auc:0.73005                                                \n",
      "[60]\teval-auc:0.73078                                                \n",
      "[70]\teval-auc:0.73172                                                \n",
      "[80]\teval-auc:0.73212                                                \n",
      "[90]\teval-auc:0.73258                                                \n",
      "[100]\teval-auc:0.73294                                               \n",
      "[110]\teval-auc:0.73333                                               \n",
      "[120]\teval-auc:0.73350                                               \n",
      "[130]\teval-auc:0.73365                                               \n",
      "[140]\teval-auc:0.73391                                               \n",
      "[150]\teval-auc:0.73398                                               \n",
      "[160]\teval-auc:0.73404                                               \n",
      "[170]\teval-auc:0.73410                                               \n",
      "[180]\teval-auc:0.73405                                               \n",
      "[190]\teval-auc:0.73400                                               \n",
      "[199]\teval-auc:0.73414                                               \n",
      " 40%|████      | 20/50 [05:39<06:04, 12.14s/trial, best loss: -0.712]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/10 09:07:37 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-auc:0.67521                                                 \n",
      "[10]\teval-auc:0.71966                                                \n",
      "[20]\teval-auc:0.72812                                                \n",
      "[30]\teval-auc:0.72910                                                \n",
      "[40]\teval-auc:0.72907                                                \n",
      "[50]\teval-auc:0.72995                                                \n",
      "[60]\teval-auc:0.73096                                                \n",
      "[70]\teval-auc:0.73145                                                \n",
      "[80]\teval-auc:0.73189                                                \n",
      "[90]\teval-auc:0.73204                                                \n",
      "[100]\teval-auc:0.73252                                               \n",
      "[110]\teval-auc:0.73289                                               \n",
      "[120]\teval-auc:0.73301                                               \n",
      "[130]\teval-auc:0.73324                                               \n",
      "[140]\teval-auc:0.73338                                               \n",
      "[150]\teval-auc:0.73348                                               \n",
      "[160]\teval-auc:0.73347                                               \n",
      "[170]\teval-auc:0.73358                                               \n",
      "[180]\teval-auc:0.73361                                               \n",
      "[190]\teval-auc:0.73368                                               \n",
      "[199]\teval-auc:0.73375                                               \n",
      " 42%|████▏     | 21/50 [06:11<07:29, 15.50s/trial, best loss: -0.734]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/10 09:08:09 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-auc:0.66813                                                 \n",
      "[10]\teval-auc:0.71752                                                \n",
      "[20]\teval-auc:0.72650                                                \n",
      "[30]\teval-auc:0.72684                                                \n",
      "[40]\teval-auc:0.72700                                                \n",
      "[50]\teval-auc:0.72808                                                \n",
      "[60]\teval-auc:0.72922                                                \n",
      "[70]\teval-auc:0.72977                                                \n",
      "[80]\teval-auc:0.73030                                                \n",
      "[90]\teval-auc:0.73070                                                \n",
      "[100]\teval-auc:0.73106                                               \n",
      "[110]\teval-auc:0.73158                                               \n",
      "[120]\teval-auc:0.73195                                               \n",
      "[130]\teval-auc:0.73226                                               \n",
      "[140]\teval-auc:0.73256                                               \n",
      "[150]\teval-auc:0.73283                                               \n",
      "[160]\teval-auc:0.73300                                               \n",
      "[170]\teval-auc:0.73317                                               \n",
      "[180]\teval-auc:0.73333                                               \n",
      "[190]\teval-auc:0.73339                                               \n",
      "[199]\teval-auc:0.73347                                               \n",
      " 44%|████▍     | 22/50 [06:42<09:39, 20.69s/trial, best loss: -0.734]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/10 09:08:38 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-auc:0.67560                                                 \n",
      "[10]\teval-auc:0.72376                                                \n",
      "[20]\teval-auc:0.73006                                                \n",
      "[30]\teval-auc:0.73077                                                \n",
      "[40]\teval-auc:0.73225                                                \n",
      "[50]\teval-auc:0.73252                                                \n",
      "[60]\teval-auc:0.73239                                                \n",
      "[70]\teval-auc:0.73244                                                \n",
      "[80]\teval-auc:0.73253                                                \n",
      "[90]\teval-auc:0.73226                                                \n",
      "[100]\teval-auc:0.73217                                               \n",
      "[110]\teval-auc:0.73213                                               \n",
      "[114]\teval-auc:0.73219                                               \n",
      " 46%|████▌     | 23/50 [06:56<10:19, 22.94s/trial, best loss: -0.734]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/10 09:08:56 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-auc:0.61092                                                 \n",
      "[10]\teval-auc:0.68293                                                \n",
      "[20]\teval-auc:0.69572                                                \n",
      "[30]\teval-auc:0.69700                                                \n",
      "[40]\teval-auc:0.69651                                                \n",
      "[50]\teval-auc:0.69508                                                \n",
      "[60]\teval-auc:0.69435                                                \n",
      "[70]\teval-auc:0.69245                                                \n",
      "[79]\teval-auc:0.69074                                                \n",
      " 48%|████▊     | 24/50 [07:36<09:23, 21.68s/trial, best loss: -0.734]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/10 09:09:41 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-auc:0.63480                                                 \n",
      "[10]\teval-auc:0.69502                                                \n",
      "[20]\teval-auc:0.70137                                                \n",
      "[30]\teval-auc:0.69725                                                \n",
      "[40]\teval-auc:0.69392                                                \n",
      "[50]\teval-auc:0.69066                                                \n",
      "[60]\teval-auc:0.68793                                                \n",
      "[66]\teval-auc:0.68617                                                \n",
      " 50%|█████     | 25/50 [08:11<11:54, 28.57s/trial, best loss: -0.734]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/10 09:10:09 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-auc:0.67609                                                 \n",
      "[10]\teval-auc:0.72341                                                \n",
      "[20]\teval-auc:0.72901                                                \n",
      "[30]\teval-auc:0.72987                                                \n",
      "[40]\teval-auc:0.73020                                                \n",
      "[50]\teval-auc:0.73097                                                \n",
      "[60]\teval-auc:0.73217                                                \n",
      "[70]\teval-auc:0.73265                                                \n",
      "[80]\teval-auc:0.73286                                                \n",
      "[90]\teval-auc:0.73289                                                \n",
      "[100]\teval-auc:0.73304                                               \n",
      "[110]\teval-auc:0.73334                                               \n",
      "[120]\teval-auc:0.73344                                               \n",
      "[130]\teval-auc:0.73350                                               \n",
      "[140]\teval-auc:0.73351                                               \n",
      "[150]\teval-auc:0.73369                                               \n",
      "[160]\teval-auc:0.73343                                               \n",
      "[170]\teval-auc:0.73313                                               \n",
      "[180]\teval-auc:0.73306                                               \n",
      "[190]\teval-auc:0.73295                                               \n",
      "[199]\teval-auc:0.73275                                               \n",
      " 52%|█████▏    | 26/50 [08:44<11:23, 28.50s/trial, best loss: -0.734]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/10 09:10:43 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-auc:0.62085                                                 \n",
      "[10]\teval-auc:0.68257                                                \n",
      "[20]\teval-auc:0.69253                                                \n",
      "[30]\teval-auc:0.69360                                                \n",
      "[40]\teval-auc:0.69153                                                \n",
      "[50]\teval-auc:0.69043                                                \n",
      "[60]\teval-auc:0.68997                                                \n",
      "[65]\teval-auc:0.68842                                                \n",
      " 54%|█████▍    | 27/50 [09:16<11:30, 30.01s/trial, best loss: -0.734]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/10 09:11:26 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-auc:0.63879                                                 \n",
      "[10]\teval-auc:0.69498                                                \n",
      "[20]\teval-auc:0.69101                                                \n",
      "[30]\teval-auc:0.68523                                                \n",
      "[40]\teval-auc:0.68108                                                \n",
      "[50]\teval-auc:0.67654                                                \n",
      "[58]\teval-auc:0.67420                                                \n",
      " 56%|█████▌    | 28/50 [10:02<12:29, 34.05s/trial, best loss: -0.734]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/10 09:12:01 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-auc:0.65392                                                 \n",
      "[10]\teval-auc:0.70700                                                \n",
      "[20]\teval-auc:0.71123                                                \n",
      "[30]\teval-auc:0.70857                                                \n",
      "[40]\teval-auc:0.70524                                                \n",
      "[50]\teval-auc:0.70300                                                \n",
      "[60]\teval-auc:0.70111                                                \n",
      "[67]\teval-auc:0.69963                                                \n",
      " 58%|█████▊    | 29/50 [10:24<11:57, 34.16s/trial, best loss: -0.734]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/10 09:12:20 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-auc:0.62204                                                 \n",
      "[10]\teval-auc:0.69469                                                \n",
      "[20]\teval-auc:0.69967                                                \n",
      "[30]\teval-auc:0.69798                                                \n",
      "[40]\teval-auc:0.69365                                                \n",
      "[50]\teval-auc:0.69099                                                \n",
      "[60]\teval-auc:0.68940                                                \n",
      "[64]\teval-auc:0.68738                                                \n",
      " 60%|██████    | 30/50 [10:50<09:52, 29.63s/trial, best loss: -0.734]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/10 09:12:48 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-auc:0.61305                                                 \n",
      "[10]\teval-auc:0.66220                                                \n",
      "[20]\teval-auc:0.66837                                                \n",
      "[30]\teval-auc:0.66856                                                \n",
      "[40]\teval-auc:0.66556                                                \n",
      "[50]\teval-auc:0.66448                                                \n",
      "[60]\teval-auc:0.66428                                                \n",
      "[64]\teval-auc:0.66229                                                \n",
      " 62%|██████▏   | 31/50 [11:21<09:17, 29.32s/trial, best loss: -0.734]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/10 09:13:21 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-auc:0.61224                                                 \n",
      "[10]\teval-auc:0.68220                                                \n",
      "[20]\teval-auc:0.69409                                                \n",
      "[30]\teval-auc:0.69721                                                \n",
      "[40]\teval-auc:0.69638                                                \n",
      "[50]\teval-auc:0.69386                                                \n",
      "[60]\teval-auc:0.69386                                                \n",
      "[70]\teval-auc:0.69259                                                \n",
      "[80]\teval-auc:0.69100                                                \n",
      " 64%|██████▍   | 32/50 [12:11<09:06, 30.39s/trial, best loss: -0.734]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/10 09:14:12 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-auc:0.61079                                                 \n",
      "[10]\teval-auc:0.66438                                                \n",
      "[20]\teval-auc:0.67794                                                \n",
      "[30]\teval-auc:0.67674                                                \n",
      "[40]\teval-auc:0.67327                                                \n",
      "[50]\teval-auc:0.66867                                                \n",
      "[60]\teval-auc:0.66581                                                \n",
      "[67]\teval-auc:0.66455                                                \n",
      " 66%|██████▌   | 33/50 [12:52<10:23, 36.67s/trial, best loss: -0.734]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/10 09:14:52 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-auc:0.60992                                                 \n",
      "[10]\teval-auc:0.64167                                                \n",
      "[20]\teval-auc:0.65629                                                \n",
      "[30]\teval-auc:0.66035                                                \n",
      "[40]\teval-auc:0.66335                                                \n",
      "[50]\teval-auc:0.66285                                                \n",
      "[60]\teval-auc:0.66218                                                \n",
      "[70]\teval-auc:0.66092                                                \n",
      "[80]\teval-auc:0.65927                                                \n",
      "[90]\teval-auc:0.65916                                                \n",
      "[96]\teval-auc:0.65795                                                \n",
      " 68%|██████▊   | 34/50 [13:43<10:00, 37.56s/trial, best loss: -0.734]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/10 09:15:46 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-auc:0.62017                                                 \n",
      "[10]\teval-auc:0.68624                                                \n",
      "[20]\teval-auc:0.69596                                                \n",
      "[30]\teval-auc:0.69667                                                \n",
      "[40]\teval-auc:0.69444                                                \n",
      "[50]\teval-auc:0.69304                                                \n",
      "[60]\teval-auc:0.69147                                                \n",
      "[70]\teval-auc:0.68936                                                \n",
      "[78]\teval-auc:0.68769                                                \n",
      " 70%|███████   | 35/50 [14:39<10:38, 42.59s/trial, best loss: -0.734]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/10 09:16:40 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-auc:0.61975                                                 \n",
      "[10]\teval-auc:0.67190                                                \n",
      "[20]\teval-auc:0.66697                                                \n",
      "[30]\teval-auc:0.66034                                                \n",
      "[40]\teval-auc:0.65405                                                \n",
      "[50]\teval-auc:0.65213                                                \n",
      "[55]\teval-auc:0.65135                                                \n",
      " 72%|███████▏  | 36/50 [15:56<10:42, 45.89s/trial, best loss: -0.734]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/10 09:17:54 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-auc:0.67918                                                 \n",
      "[10]\teval-auc:0.72364                                                \n",
      "[20]\teval-auc:0.72973                                                \n",
      "[30]\teval-auc:0.72877                                                \n",
      "[40]\teval-auc:0.72852                                                \n",
      "[50]\teval-auc:0.72786                                                \n",
      "[60]\teval-auc:0.72741                                                \n",
      "[68]\teval-auc:0.72686                                                \n",
      " 74%|███████▍  | 37/50 [16:12<11:46, 54.35s/trial, best loss: -0.734]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/10 09:18:08 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-auc:0.62250                                                 \n",
      "[10]\teval-auc:0.67908                                                \n",
      "[20]\teval-auc:0.67697                                                \n",
      "[30]\teval-auc:0.67240                                                \n",
      "[40]\teval-auc:0.66904                                                \n",
      "[50]\teval-auc:0.66616                                                \n",
      "[58]\teval-auc:0.66422                                                \n",
      " 76%|███████▌  | 38/50 [16:39<08:24, 42.04s/trial, best loss: -0.734]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/10 09:18:35 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-auc:0.63698                                                 \n",
      "[10]\teval-auc:0.70644                                                \n",
      "[20]\teval-auc:0.71497                                                \n",
      "[30]\teval-auc:0.71716                                                \n",
      "[40]\teval-auc:0.71445                                                \n",
      "[50]\teval-auc:0.71267                                                \n",
      "[60]\teval-auc:0.71164                                                \n",
      "[70]\teval-auc:0.70956                                                \n",
      "[79]\teval-auc:0.70801                                                \n",
      " 78%|███████▊  | 39/50 [17:22<06:53, 37.58s/trial, best loss: -0.734]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/10 09:19:29 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-auc:0.62762                                                 \n",
      "[10]\teval-auc:0.69497                                                \n",
      "[20]\teval-auc:0.70154                                                \n",
      "[30]\teval-auc:0.69976                                                \n",
      "[40]\teval-auc:0.69703                                                \n",
      "[50]\teval-auc:0.69459                                                \n",
      "[60]\teval-auc:0.69301                                                \n",
      "[66]\teval-auc:0.69086                                                \n",
      " 80%|████████  | 40/50 [17:59<07:07, 42.72s/trial, best loss: -0.734]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/10 09:19:58 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-auc:0.60807                                                 \n",
      "[10]\teval-auc:0.63698                                                \n",
      "[20]\teval-auc:0.64307                                                \n",
      "[30]\teval-auc:0.64082                                                \n",
      "[40]\teval-auc:0.64076                                                \n",
      "[50]\teval-auc:0.63943                                                \n",
      "[60]\teval-auc:0.63810                                                \n",
      "[70]\teval-auc:0.63759                                                \n",
      "[72]\teval-auc:0.63789                                                \n",
      " 82%|████████▏ | 41/50 [18:37<05:47, 38.59s/trial, best loss: -0.734]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/10 09:20:39 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-auc:0.61089                                                 \n",
      "[10]\teval-auc:0.66303                                                \n",
      "[20]\teval-auc:0.66801                                                \n",
      "[30]\teval-auc:0.66640                                                \n",
      "[40]\teval-auc:0.66383                                                \n",
      "[50]\teval-auc:0.66194                                                \n",
      "[60]\teval-auc:0.66075                                                \n",
      "[67]\teval-auc:0.65826                                                \n",
      " 84%|████████▍ | 42/50 [20:45<05:13, 39.21s/trial, best loss: -0.734]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/10 09:22:47 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-auc:0.61927                                                 \n",
      "[10]\teval-auc:0.67444                                                \n",
      "[20]\teval-auc:0.67683                                                \n",
      "[30]\teval-auc:0.67076                                                \n",
      "[40]\teval-auc:0.66492                                                \n",
      "[50]\teval-auc:0.66182                                                \n",
      "[60]\teval-auc:0.66117                                                \n",
      "[65]\teval-auc:0.65980                                                \n",
      " 86%|████████▌ | 43/50 [21:11<07:41, 65.96s/trial, best loss: -0.734]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/10 09:23:07 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-auc:0.65306                                                 \n",
      "[10]\teval-auc:0.71543                                                \n",
      "[20]\teval-auc:0.71862                                                \n",
      "[30]\teval-auc:0.71664                                                \n",
      "[40]\teval-auc:0.71528                                                \n",
      "[50]\teval-auc:0.71480                                                \n",
      "[60]\teval-auc:0.71343                                                \n",
      "[70]\teval-auc:0.71291                                                \n",
      " 88%|████████▊ | 44/50 [21:27<05:13, 52.20s/trial, best loss: -0.734]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/10 09:23:23 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-auc:0.62079                                                 \n",
      "[10]\teval-auc:0.68970                                                \n",
      "[20]\teval-auc:0.69731                                                \n",
      "[30]\teval-auc:0.69801                                                \n",
      "[40]\teval-auc:0.69491                                                \n",
      "[50]\teval-auc:0.69254                                                \n",
      "[60]\teval-auc:0.69078                                                \n",
      "[66]\teval-auc:0.68895                                                \n",
      " 90%|█████████ | 45/50 [21:50<03:25, 41.06s/trial, best loss: -0.734]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/10 09:23:48 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-auc:0.61387                                                 \n",
      "[10]\teval-auc:0.62516                                                \n",
      "[20]\teval-auc:0.62298                                                \n",
      "[30]\teval-auc:0.62132                                                \n",
      "[40]\teval-auc:0.62349                                                \n",
      "[50]\teval-auc:0.62330                                                \n",
      "[58]\teval-auc:0.62225                                                \n",
      " 92%|█████████▏| 46/50 [22:10<02:24, 36.24s/trial, best loss: -0.734]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/10 09:24:05 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-auc:0.60167                                                 \n",
      "[10]\teval-auc:0.64483                                                \n",
      "[20]\teval-auc:0.65690                                                \n",
      "[30]\teval-auc:0.65999                                                \n",
      "[40]\teval-auc:0.66015                                                \n",
      "[50]\teval-auc:0.66076                                                \n",
      "[60]\teval-auc:0.66061                                                \n",
      "[70]\teval-auc:0.65894                                                \n",
      "[80]\teval-auc:0.65749                                                \n",
      "[90]\teval-auc:0.65856                                                \n",
      "[100]\teval-auc:0.65852                                               \n",
      "[101]\teval-auc:0.65863                                               \n",
      " 94%|█████████▍| 47/50 [23:07<01:31, 30.56s/trial, best loss: -0.734]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/10 09:25:10 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-auc:0.64125                                                 \n",
      "[10]\teval-auc:0.71102                                                \n",
      "[20]\teval-auc:0.71701                                                \n",
      "[30]\teval-auc:0.71690                                                \n",
      "[40]\teval-auc:0.71330                                                \n",
      "[50]\teval-auc:0.71118                                                \n",
      "[60]\teval-auc:0.70889                                                \n",
      "[70]\teval-auc:0.70651                                                \n",
      "[75]\teval-auc:0.70482                                                \n",
      " 96%|█████████▌| 48/50 [23:41<01:22, 41.26s/trial, best loss: -0.734]"
     ]
    }
   ],
   "source": [
    "# Search space for hyperopt\n",
    "search_space = {\n",
    "    'max_depth': scope.int(hp.quniform('max_depth', 4, 100, 1)),\n",
    "    'learning_rate': hp.loguniform('learning_rate', -3, 0),\n",
    "    'reg_alpha': hp.loguniform('reg_alpha', -5, -1),\n",
    "    'reg_lambda': hp.loguniform('reg_lambda', -6, -1),\n",
    "    'min_child_weight': hp.loguniform('min_child_weight', -1, 3),\n",
    "    'subsample': hp.uniform('subsample', 0.5, 1.0),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1.0),\n",
    "}\n",
    "\n",
    "# Objective function for hyperopt\n",
    "def objective(params):\n",
    "    # Calculate imbalance ratio\n",
    "    neg, pos = np.bincount(y_train)\n",
    "    scale_pos_weight = neg / pos\n",
    "\n",
    "    # Add required static params\n",
    "    params['objective'] = 'binary:logistic'\n",
    "    params['seed'] = 42\n",
    "    params['eval_metric'] = 'auc'\n",
    "    params['scale_pos_weight'] = scale_pos_weight\n",
    "\n",
    "    run_name = f\"xgb-md{params['max_depth']}-lr{params['learning_rate']:.3f}\"\n",
    "\n",
    "    with mlflow.start_run(nested=True, run_name=run_name):\n",
    "        mlflow.set_tag(\"model\", \"XGBoost\")\n",
    "        mlflow.set_tag(\"engineer\", \"adeakinwe\")\n",
    "\n",
    "        mlflow.log_param(\"train_data\", \"../processed_data/X_train.parquet\")\n",
    "        mlflow.log_param(\"val_data\", \"../processed_data/X_val.parquet\")\n",
    "\n",
    "        mlflow.log_params({k: round(v, 5) if isinstance(v, float) else v for k, v in params.items()})\n",
    "\n",
    "        dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "        dval = xgb.DMatrix(X_val, label=y_val)\n",
    "\n",
    "        model = xgb.train(\n",
    "            params,\n",
    "            dtrain,\n",
    "            num_boost_round=200,\n",
    "            evals=[(dval, 'eval')],\n",
    "            early_stopping_rounds=50,\n",
    "            verbose_eval=10\n",
    "        )\n",
    "\n",
    "        y_pred_proba = model.predict(dval)\n",
    "        y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "\n",
    "        accuracy = round(accuracy_score(y_val, y_pred), 3)\n",
    "        auc = round(roc_auc_score(y_val, y_pred_proba), 3)\n",
    "\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.log_metric(\"auc\", auc)\n",
    "\n",
    "        mlflow.xgboost.log_model(model, artifact_path=\"models\")\n",
    "\n",
    "        return {'loss': -auc, 'status': STATUS_OK}\n",
    "\n",
    "# Run outer MLflow parent run\n",
    "with mlflow.start_run(run_name=\"xgboost-hyperopt\"):\n",
    "    trials = Trials()\n",
    "    best_result = fmin(\n",
    "        fn=objective,\n",
    "        space=search_space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=50,\n",
    "        trials=trials\n",
    "    )\n",
    "\n",
    "    # Log best hyperparameters found\n",
    "    mlflow.log_params({f\"best_{k}\": v for k, v in best_result.items()})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05bd775",
   "metadata": {},
   "source": [
    "train and save best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5431da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#best params from hyper parameter tuning\n",
    "best_params = {\n",
    "    'max_depth': 4,\n",
    "    'learning_rate': 0.0566,\n",
    "    'reg_alpha': 0.04744,\n",
    "    'reg_lambda': 0.04301,\n",
    "    'min_child_weight': 1.42993,\n",
    "    'subsample': 0.65727,\n",
    "    'colsample_bytree': 0.60704,\n",
    "    'objective': 'binary:logistic',\n",
    "    'seed': 42,\n",
    "    'eval_metric': 'auc',\n",
    "    'scale_pos_weight': 11.38747\n",
    "}\n",
    "\n",
    "with mlflow.start_run(run_name=\"xgboost-final-auc\"):\n",
    "\n",
    "    mlflow.set_tag(\"model\", \"XGBoost\")\n",
    "    mlflow.set_tag(\"engineer\", \"adeakinwe\")\n",
    "    mlflow.log_param(\"train_data_path\", \"../processed_data/X_train.parquet\")\n",
    "    mlflow.log_param(\"val_data_path\", \"../processed_data/X_val.parquet\")\n",
    "\n",
    "    mlflow.log_params(best_params)\n",
    "\n",
    "    # Prepare DMatrix\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dval = xgb.DMatrix(X_val, label=y_val)\n",
    "\n",
    "    # Train model\n",
    "    model = xgb.train(\n",
    "        best_params,\n",
    "        dtrain,\n",
    "        num_boost_round=200,\n",
    "        evals=[(dval, 'eval')],\n",
    "        early_stopping_rounds=50,\n",
    "        verbose_eval=10\n",
    "    )\n",
    "\n",
    "    # Evaluate\n",
    "    y_proba = model.predict(dval)\n",
    "    auc = round(roc_auc_score(y_val, y_proba), 3)\n",
    "    mlflow.log_metric(\"auc\", auc)\n",
    "\n",
    "    # Log model (native)\n",
    "    mlflow.xgboost.log_model(model, artifact_path=\"models/xgboost_model\")\n",
    "\n",
    "    # Dump model + vectorizer together\n",
    "    model_bundle = {\n",
    "        \"model\": model,\n",
    "        \"vectorizer\": dv  # dict_vectorizer\n",
    "    }\n",
    "\n",
    "    bundle_path = \"../models/xgb_credit_pred.bin\"\n",
    "    with open(bundle_path, \"wb\") as f_out:\n",
    "        pickle.dump(model_bundle, f_out)\n",
    "\n",
    "    mlflow.log_artifact(bundle_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5b9b69",
   "metadata": {},
   "source": [
    "load model with mlflow run id and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bed7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "logged_model = 'runs:/2c2f5792316545ed84ddf88b09b072a9/models/xgboost_model'\n",
    "\n",
    "# Load model as a PyFuncModel.\n",
    "loaded_model = mlflow.pyfunc.load_model(logged_model)\n",
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409e7fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_model = mlflow.xgboost.load_model(logged_model)\n",
    "xgboost_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93b63a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgboost_model.predict(dval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[:10]"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
